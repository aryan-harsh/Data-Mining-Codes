# -*- coding: utf-8 -*-
"""Data Mining apriori Ass1 final.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1yTatYR5wDL225kLCdSbN9gG4GDvny6yx
"""

import pandas as pd
import numpy as np
from tqdm import tqdm
import itertools

with open('retail.dat') as f:
    data = [set(i.strip().split()) for i in f]
    data = data[:10000]
    f.close()

data

all_items = set()
with open('retail.dat','r') as f:
    count=0
    for line in tqdm(f):
        line = set(line.strip().split())
        all_items = all_items.union(line)
        count+=1
        if count==10000:
          break
    f.close()

all_items = list(all_items)

len(all_items)

all_items_set = set()
for i in tqdm(all_items):
    x = set()
    x.add(i)
    x = frozenset(x)
    all_items_set.add(x)

all_items_set

len(all_items_set)

min_support = 200
min_confidence = 0.6

def create_Lk(min_support,data,item_sets):
    freq_dict = {}
    n = len(data)
    for i in item_sets:
        for trans in data:
            if i.issubset(trans):
                if i in freq_dict:
                    freq_dict[i] += 1
                else:
                    freq_dict[i] = 1
    
    freq_dict = {i:j for i,j in freq_dict.items() if j>= min_support}
    
    return freq_dict

def printdf(final_table):
  arr = [[], []]
  for i in range(len(list(final_table.items()))):
    arr[0].append(list(final_table.items())[i][0])
    arr[1].append(list(final_table.items())[i][1])
  
  df = pd.DataFrame(np.array(arr))
  return df

def apriori(data,item_sets,min_support,min_confidence):
    L_table_list = {}
    count = 1
    L_table_list[count] = create_Lk(min_support,data,item_sets)
    L = L_table_list[1]
    count += 1
    
    while len(L)!=0:
        new_item_set = set(L.keys())
        new_item_set = set([i.union(j) for i in new_item_set for j in new_item_set if len(i.union(j))==count])
        L = create_Lk(min_support,data,new_item_set)
        L_table_list[count] = L
        
        count += 1

        if len(L)!=0:
          final_table = L

        print("Length of table reduced to: "+str(len(L)))

    print(final_table)
    
    return final_table, L_table_list

final_table, L_table_list = apriori(data,all_items_set,min_support,min_confidence)

df = printdf(final_table)
df

possible_combinations = {}
for item_set, support_count in final_table.items():
  possible_combinations[item_set] = list()
  for sz in range(1, len(item_set)):
    for comb in itertools.combinations(item_set, sz):
        possible_combinations[item_set].append(comb)
    
print(possible_combinations)

def check(comb1, comb2, L_table_list, min_confidence):
  union_comb = (comb1.union(comb2))
  p1 = L_table_list[len(union_comb)][union_comb]
  p2 = L_table_list[len(comb2)][comb2]

  p = float(p1/p2)

  if(p>=min_confidence):
    return True
  return False

assoc_rules = {}
for item_set, combinations in possible_combinations.items():
  assoc_rules[item_set] = []
  for i in range(len(combinations)):
    for j in range(len(combinations)):

      comb1 = frozenset(combinations[i])
      comb2 = frozenset(combinations[j])

      if(comb1.union(comb2)==item_set and  comb1.isdisjoint(comb2)):
        rule = {}

        if check(comb1, comb2, L_table_list, min_confidence):
          rule[comb1] = comb2
          assoc_rules[item_set].append(rule)

for item_set, rules in assoc_rules.items():
  print(item_set)
  print("--------------------------------------------")

  for rule in rules:
    key = list(rule.keys())[0]
    val = list(rule.values())[0]

    print(str(key)+"----->"+str(val))

  print("\n\n")

